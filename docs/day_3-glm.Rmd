---
title: "DAY 3 - GENERALIZED LINEAR REGRESSION"
author: "Tamas Nagy"
date: '2022-07-14'
output: 
  html_document:
   theme: spacelab
   code_download: true
   toc: true
   toc_float: true
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(broom) # Tidying model output
library(titanic) # This is for the dataset

theme_set(theme_light())
```

# Predicting the Titanic survivors

We will use the titanic dataset to predict who died and who survived.
We use a model that includes sex, the price of the ticket, the number of spouses and sibilings, and the number of parents and children. We also include the interactions of the ticket price and sex.

```{r}
# We will use the titanic dataset
titanic <- 
    titanic_train %>% 
    rename_all(str_to_lower) %>% 
    as_tibble() %>% 
    # We will center the fare variable
    mutate(fare = scale(fare, scale = FALSE) %>% as.numeric()) 

# Check codebook
?titanic_train

# Fit logistic binomial regression
titanic_fit <- glm(survived ~ fare  * sex + sibsp + parch, 
                   family = "binomial", 
                   data = titanic)

summary(titanic_fit)
tidy(titanic_fit)
glance(titanic_fit)
```
To get the odds ratio, use the `exp()` function on the coefficients.

We can also calculate confidence intervals for the ORs.
```{r}
exp(confint(titanic_fit))
```

But instead, we can use the `tidy()` function to exponentiate coefficients and provide confidence intervals. 

```{r}
tidy(titanic_fit, conf.int = TRUE, exponentiate = TRUE)
```

Let's plot the data. Please mind that you need to tweek the arguments for `geom_smooth()` to fit a binomial logistic function.

# Plotting logistic regression
```{r}
# In this plot, we will only include sex and ticket price as predictors.
ggplot(titanic) +
    aes(y = survived, x = fare, group = sex, color = sex) +
    geom_point() +
    geom_smooth(method = "glm", 
                method.args = list(family = "binomial")) +
    coord_cartesian(ylim = c(0, 1)) +
    scale_y_continuous(labels = scales::percent_format())
```


## Evaluating a logistic regression model

R2 cannot be calculated for glm as for linear regression, and also might not be the most useful metric. However, it is possible to calculate pseudo R2. 
The `{performance}` package offers several calculation methods, and also chooses the best one for the model. For a more detailed discussion on pseudo R2s, see: https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-what-are-pseudo-r-squareds/. 

```{r}
library(performance)
r2(titanic_fit)
```

## Model predictions 

To get the predictions of the model, we can use the `augment()` function from the `{broom}` package.
The prediction of the GLM can either be on the scale of the predictors ("link"), or in the scale of the outcome ("response"). Thus for a binomial model the default predictions are of log-odds (probabilities on logit scale) and type = "response" gives the predicted probabilities. 

```{r}
augment(titanic_fit, type.predict = "response")
```

Calculating and plotting the ROC curve, and calculating the ROC AUC are easy with the `{performance}` package.

```{r}
surv_roc <- performance_roc(titanic_fit) 

# ROC curve
plot(surv_roc)

# ROC AUC
surv_roc

```

## Reporting logistic regression paramters

```{r}
library(sjPlot)
tab_model(titanic_fit,
          show.aic = TRUE,
          show.loglik = TRUE,
          collapse.se = TRUE
)

```

# Poisson regression
Use poisson regression to predict a count-type variable (integer values, and totally left-skewed).
We are predicting the number of family members on board, by age

```{r}
titanic <-
    titanic %>% 
    mutate(family = sibsp + parch)

# Check the distribution of family variable
qplot(titanic$family)
```

Yep, definitely poisson distribution
Fitting a poisson regression is not difficult, just use the family = "poisson" parameter.

```{r}
family_fit_pois <- 
  glm(family ~ age, family = "poisson", data = titanic)

```


Check the results. They look very much like the output of logistic regression, only the model summary statistics are different

```{r}
summary(family_fit_pois)
tidy(family_fit_pois, exponentiate = TRUE, conf.int = TRUE)
glance(family_fit_pois)
```

```{r}
titanic %>% 
  ggplot() +
  aes(y = family, x = age) +
  geom_point(alpha = .4) +
  geom_smooth(method = "glm", 
              method.args = list(family = "poisson"))

```


However the poisson regression is not appropriate for data that has a large dispersion. Dispersion should not be significantly larger than 1.
We can test the dispersion and zero-inflation like this:

```{r}
check_overdispersion(family_fit_pois)
check_zeroinflation(family_fit_pois)
```

We have to run a negative binomial regression, since dispersion is 2.2 (variance is more than 2x the mean). The model also shows zero-inflation. However, we will only discuss that later.

```{r}
# We won't load the MASS package, as it overwrites some functions
family_fit_nb <- MASS::glm.nb(family ~ age, data = titanic)

summary(family_fit_nb)
tidy(family_fit_nb, exponentiate = TRUE, conf.int = TRUE)
glance(family_fit_nb)
```

Let's plot this. Mind the geom_smooth() parameters!

```{r}
titanic %>% 
    ggplot() +
    aes(y = family, x = age) +
    geom_point() +
    geom_smooth(method = MASS::glm.nb)
```

When reporting poisson/negative binomial regression, you have to report the same things as in logistic regression.

```{r}
tab_model(family_fit_nb)
```

# Cumulative Link Model for Ordinal data
We will use a dataset about the ratings of NYC restaurants from A to C
```{r}
library(ordinal)
library(janitor)

restaurants <- read_csv("https://data.cityofnewyork.us/api/views/43nn-pn8j/rows.csv")

restaurants

```

```{r}
# We drop some irrelevant variables, filter a few values, tidy variable names
# TODO: move this to the dataset generation
rest_clean <-
  restaurants %>% 
  janitor::clean_names() %>% 
  select(boro, cuisine_description, critical_flag, score, grade) %>% 
  drop_na() %>% 
  filter(grade %in% c("A", "B", "C")) %>% 
  filter(cuisine_description %in% c("African", "American", "Asian", "Latin", "Middle Eastern")) %>% 
  filter(boro %in% c ("Bronx", "Brooklyn", "Manhattan", "Queens", "Staten Island"))

head(rest_clean)
```


```{r}
# dependent variable needs to be a factor
rest_clean <- 
  rest_clean %>% 
  mutate(grade = as.factor(grade),
         cuisine_description = fct_relevel(cuisine_description, "American"))

# Building the cumulative link model
# Comparing to American cousine, and the BRONX
clm1 <- clm(grade ~ cuisine_description + boro, data = rest_clean)
summary(clm1)
```

```{r}
# Running post-hoc tests
emmeans::emmeans(clm1, "cuisine_description", "boro")
```

Testing the model assumption, the proportional odd's ratio  with either the nominal_test or scale_test function. 

```{r}
nominal_test(clm1)
scale_test(clm1)
```

Let's plot our data

```{r}
ggplot(rest_clean) +
  aes(x = cuisine_description, y = grade)
  geom_boxplot(size = .75) +
  geom_jitter(alpha = .5) +
  facet_wrap("boro") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))
```


