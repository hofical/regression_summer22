---
title: "DAY 3 - GENERALIZED LINEAR REGRESSION"
author: "Tamas Nagy"
date: '2022-07-14'
output: 
  html_document:
   theme: spacelab
   code_download: true
   toc: true
   toc_float: true
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: sentence
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE)

suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(here))
suppressPackageStartupMessages(library(sjPlot))
library(broom)
library(performance)

theme_set(theme_light())
```

# Predicting the Titanic survivors

We will use the titanic dataset to predict who died and who survived.
We use a model that includes sex, the price of the ticket, the number of spouses and sibilings, and the number of parents and children. We also include the interactions of the ticket price and sex.

```{r}
library(titanic) # This is for the dataset

titanic <- 
    titanic_train %>% 
    rename_all(str_to_lower) %>% 
    as_tibble() %>% 
    # We will center the fare variable
    mutate(fare = scale(fare, scale = FALSE) %>% as.numeric()) 

# Check codebook
# ?titanic_train

# Fit logistic binomial regression
titanic_fit <- glm(survived ~ fare  * sex + sibsp + parch, 
                   family = "binomial", 
                   data = titanic)

summary(titanic_fit)
tidy(titanic_fit)
glance(titanic_fit)
```
To get the odds ratio, use the `exp()` function on the coefficients.

We can also calculate confidence intervals for the ORs.
```{r}
exp(confint(titanic_fit))
```

But instead, we can use the `tidy()` function to exponentiate coefficients and provide confidence intervals. 

```{r}
tidy(titanic_fit, conf.int = TRUE, exponentiate = TRUE)
```

Let's plot the data. Please mind that you need to tweek the arguments for `geom_smooth()` to fit a binomial logistic function.

## Plotting logistic regression
```{r}
# In this plot, we will only include sex and ticket price as predictors.
ggplot(titanic) +
    aes(y = survived, x = fare, group = sex, color = sex) +
    geom_point() +
    geom_smooth(method = "glm", 
                method.args = list(family = "binomial")) +
    coord_cartesian(ylim = c(0, 1)) +
    scale_y_continuous(labels = scales::percent_format())
```


## Evaluating a logistic regression model

R2 cannot be calculated for glm as for linear regression, and also might not be the most useful metric. However, it is possible to calculate pseudo R2. 
The `{performance}` package offers several calculation methods, and also chooses the best one for the model. For a more detailed discussion on pseudo R2s, see: https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-what-are-pseudo-r-squareds/. 

```{r}
r2(titanic_fit)
```

## Model predictions 

To get the predictions of the model, we can use the `augment()` function from the `{broom}` package.
The prediction of the GLM can either be on the scale of the predictors ("link"), or in the scale of the outcome ("response"). Thus for a binomial model the default predictions are of log-odds (probabilities on logit scale) and type = "response" gives the predicted probabilities. 

```{r}
augment(titanic_fit, type.predict = "response")
```


## Creating an ROC curve

Calculating and plotting the ROC curve, and calculating the ROC AUC are easy with the `{performance}` package.

```{r}
surv_roc <- performance_roc(titanic_fit) 

# ROC curve
plot(surv_roc)

# ROC AUC
surv_roc

```

## Reporting logistic regression parameters

```{r}

tab_model(titanic_fit,
          show.aic = TRUE,
          show.loglik = TRUE,
          collapse.se = TRUE
)

```

# Multinomial logistic regression

In multinomial regression, we are performing classification for an outcome that can take more than two nominal values that cannot be ordered.
We are going to classify penguins from the `{palmerpenguins}` dataset into three possible categories. Data source: https://allisonhorst.github.io/palmerpenguins/    

```{r}
library(palmerpenguins)
library(nnet)# Contains the multinom function

penguins

# The number of obervations for each species
penguins %>% 
  count(species)

penguin_mn <- multinom(species ~ bill_length_mm +
                       flipper_length_mm, 
                       data = penguins)
summary(penguin_mn)
```

The `summary()` function for a `multinom` object is not that informative, e.g. we don't get tests statistics and p values. We can get those using the `tidy()` function, or `tab_model()`.  
  What is immediately obvious is that we get more than one sets of coefficients and std.errors. This is because coefficients are calculated for each outcome with respect to the baseline category.  
  A one-unit increase in the predictor variable is associated with the increase in the log odds of classifying a penguin into one category compared to the baseline category.  
  Instead of using the default coefficients, it is easier to interpret them as odds ratios after we exponentiate them.

```{r}
tidy(penguin_mn, exponentiate = TRUE, conf.int = TRUE)
tab_model(penguin_mn)
```


## Confusion matrix
The model performance can be measured in multiple ways. We can calculate pseudo R2, look at the confusion matrix. 

```{r}
library(yardstick) # for model performance functions

r2(penguin_mn)

penguins %>% 
  mutate(pred = predict(penguin_mn, newdata = .)) %>% 
  conf_mat(truth = species, estimate = pred) %>% 
  autoplot(type = "heatmap")

```

We can also calculate and visualize the ROC curve, and ROC AUC. This is a bit more complicated for multiclass ROC, as we need to calculate a ROC for pairwise classifications. 

## Multiclass roc curve
```{r}
library(pROC) # Can calculate multiclass ROC, but plotting requires cutomization
library(patchwork) # Tool for putting togeter multiple plots

# ROC curve
# Create predictions (probabilities)
penguin_prob <-
  penguins %>% 
  mutate(pred = predict(penguin_mn, newdata = ., type = "prob")) 

# Calculate the ROC tables
penguin_roc <-
  multiclass.roc(penguin_prob$species, penguin_prob$pred)

# Create ROC plots
roc_plots <- 
  map2(penguin_roc[['rocs']], names(penguin_roc[['rocs']]),
       ~ggroc(.x) + 
        ggtitle(.y))

# Put all plots into a single plot
roc_plots[[1]] + roc_plots[[2]] + plot_spacer() + roc_plots[[3]] +
plot_layout(ncol = 2, guides = "collect") 

# Multiclass ROC AUC
penguin_roc

```

# Count regression (Poisson)

Use Poisson regression to predict a count-type variable (integer values, and totally left-skewed).
We are predicting the number of family members on board, by age

```{r}
titanic <-
    titanic %>% 
    mutate(family = sibsp + parch)

# Check the distribution of family variable
qplot(titanic$family)
```

Yep, definitely Poisson distribution
Fitting a Poisson regression is not difficult, just use the `family = "poisson"` parameter.

```{r}
family_fit_pois <- 
  glm(family ~ age, family = "poisson", data = titanic)

```


Check the results. They look very much like the output of logistic regression, only the model summary statistics are different

```{r}
summary(family_fit_pois)
tidy(family_fit_pois, exponentiate = TRUE, conf.int = TRUE)
glance(family_fit_pois)
```

## Plotting Poisson regression

```{r}
titanic %>% 
  ggplot() +
  aes(y = family, x = age) +
  geom_point(alpha = .4) +
  geom_smooth(method = "glm", 
              method.args = list(family = "poisson"))

```

## Checking assumptions

However the Poisson regression is not appropriate for data that has a large dispersion. Dispersion should not be significantly larger than 1.
We can test the dispersion and zero-inflation like this:

```{r}
check_overdispersion(family_fit_pois)
check_zeroinflation(family_fit_pois)
```

# Negative binomial regression

We have to run a negative binomial regression, since dispersion is 2.2 (variance is more than 2x the mean). The model also shows zero-inflation. However, we will only discuss that later.

```{r}
# We won't load the MASS package, as it overwrites some functions
family_fit_nb <- MASS::glm.nb(family ~ age, data = titanic)

summary(family_fit_nb)
tidy(family_fit_nb, exponentiate = TRUE, conf.int = TRUE)
glance(family_fit_nb)
```

Let's plot this. Mind the `geom_smooth()` parameters!

```{r}
titanic %>% 
    ggplot() +
    aes(y = family, x = age) +
    geom_point() +
    geom_smooth(method = MASS::glm.nb)
```

When reporting Poisson/negative binomial regression, you have to report the same things as in logistic regression.

```{r}
tab_model(family_fit_nb, 
          show.aic = TRUE)
```

# Zero-inflated models

As we saw earlier, the data shows zero-inflation that should be addressed.
The ZI model effectively fits two regressions: one binomial regression where we model if there were at least one observation. The other is a count model where we are predicting a number that is larger than zero.
It is possible to use different predictors for the two models separated by `|` (not mandatory). The model coefficients can be exponentiated and interpreted as Risk Ratios.

```{r}
library(pscl)

titanic_zinb <- zeroinfl(family ~ age | age + fare, 
                        dist = "negbin",
                        data = titanic)

summary(titanic_zinb)
# The following function does the exponentiation by default
tab_model(titanic_zinb)

```

Notice the Log(theta) predictor in the model summary. This is a feature of negative binomial regression, and it means the dispersion term in the model. 
Read more about it here: https://stats.stackexchange.com/questions/10419/what-is-theta-in-a-negative-binomial-regression-fitted-with-r.

# Cumulative Link Model for Ordinal data

We predict ordered categories.
We will use a dataset about the ratings of NYC restaurants from A to C
```{r}
restaurants_raw <- read_csv(here("data/nyc_restaurants.csv"))

restaurants_raw

```

In order to run an ordinal regression, we need to establish the order of values in the outcome variable by making it a factor. 

```{r}
library(ordinal)
library(parameters)

restaurants <- 
  restaurants_raw %>% 
  mutate(grade = as.factor(grade),
         # Setting the baseline for the cousine decription to other
         cuisine_description = fct_relevel(cuisine_description, "Other"),
         boro = fct_relevel(boro, "Manhattan"))

# Building the cumulative link model
clm1 <- clm(grade ~ cuisine_description + boro, data = restaurants)
summary(clm1)

tab_model(clm1)

clm_coefs <- 
  tidy(clm1, exponentiate = TRUE) %>% 
  arrange(-estimate)

model_parameters(clm1, exponentiate = TRUE) %>% 
  as_tibble() %>% 
  filter(Component == "location") %>% 
  mutate(Parameter = fct_reorder(Parameter, Coefficient)) %>% 
  ggplot() +
  aes(y = Parameter, 
      x = Coefficient, 
      xmin = CI_low, xmax = CI_high) +
  geom_vline(xintercept = 0, lty = "dashed") +
  geom_pointrange() +
  ylab(NULL)
  
```

Testing the model assumption, the proportional odd's ratio  with either the `nominal_test()` or `scale_test()` function. 

```{r}
nominal_test(clm1)
scale_test(clm1)
```

Let's plot the data!

```{r}
restaurants %>% 
  count(cuisine_description, boro, grade) %>% 
  ggplot() +
  aes(y = cuisine_description, x = grade, fill = n) +
  geom_tile(alpha = .9) +
  scale_fill_viridis_c() +
  facet_wrap("boro") +
  ylab(NULL)
```


